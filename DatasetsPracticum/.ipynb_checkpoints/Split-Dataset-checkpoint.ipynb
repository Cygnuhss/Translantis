{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea behind splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one big text file containing 200 documents.\n",
    "\n",
    "All these documents contain (at the very least):\n",
    "* title\n",
    "* publish date\n",
    "* body\n",
    "* document delimiter\n",
    "* some garbage text such as hyperlinks\n",
    "\n",
    "First split the large file into 200 individual documents based on the delimiter.<br>\n",
    "Preprocess and remove most of the garbage text.<br>\n",
    "Save the individual documents.<br>\n",
    "\n",
    "Aggregate the documents by year:\n",
    "* find title\n",
    "* find body\n",
    "* find publish date\n",
    "\n",
    "Create a file for each year of the publish dates.\n",
    "Add to these files:\n",
    "* document title\n",
    "* document body<br>\n",
    "only if the publish date's year matches the filename.\n",
    "\n",
    "\n",
    "*You can skip the code below (but do run it for initialisation purposes).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some initialisation code.\n",
    "\n",
    "# Load necessary modules.\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Set the folder in which individual files will be stored.\n",
    "DOCUMENTS_FOLDER = \"./documents\"\n",
    "\n",
    "\n",
    "class Date:\n",
    "    def __init__(self, day, month, year):\n",
    "        self.day = day\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{} {} {}\".format(self.day, self.month, self.year)\n",
    "\n",
    "    def isValid(self):\n",
    "        return self.day != -1 and self.month != -1 and self.year != -1\n",
    "\n",
    "def createDate(dateString):\n",
    "    \"\"\"A dateString is of the following format:\n",
    "        dd month yyyy\n",
    "    Return a Date that has a selectable day, month and year.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dateString = dateString.replace(\",\", \"\")\n",
    "        dateStringSplit = dateString.split(\" \")\n",
    "        if dateStringSplit[0].isdigit():\n",
    "            day = dateStringSplit[0]\n",
    "            month = dateStringSplit[1]\n",
    "        else:\n",
    "            day = dateStringSplit[1]\n",
    "            month = dateStringSplit[0]\n",
    "        year = dateStringSplit[2]\n",
    "        return Date(day, month, year)\n",
    "    except IndexError:\n",
    "        return Date(-1, -1, -1)\n",
    "    \n",
    "    \n",
    "class Document:\n",
    "    def __init__(self, title, date, body):\n",
    "        self.title = title\n",
    "        self.date = date\n",
    "        self.body = body\n",
    "\n",
    "    def __repr__(self):\n",
    "        MAX_LENGTH = 100\n",
    "        body = self.body if len(self.body) < MAX_LENGTH else self.body[:MAX_LENGTH]\n",
    "        return \"{}, {}: {}\".format(self.title, self.date, body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The interesting code starts below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset in individual documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the downloaded dataset file and store in variable 'lines'.\n",
    "lines = []\n",
    "with open('dataset3.txt', 'r') as f:\n",
    "    lines = f.read()\n",
    "    \n",
    "print(\"First 500 characters of the data:\\n{}\".format(lines[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newDocumentExpression matches text of the form: \"123 of 200 DOCUMENTS\".\n",
    "# \\d matches digits [0-9].\n",
    "# For more regular expressions, see RegularExpressions-Example.ipynb\n",
    "newDocumentExpression = r\"\\b\\d+\\b of \\b\\d+\\b DOCUMENTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the document in several documents based on the newDocumentExpression.\n",
    "# Skip the first element (index 0) as it contains all text BEFORE the first document.\n",
    "# Example:\n",
    "#     Text before Article\n",
    "#     1 of 200 DOCUMENTS\n",
    "#     Title of Article\n",
    "#     Body of Article\n",
    "documents = re.split(newDocumentExpression, lines)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if all documents are found.\n",
    "# The length (amount) of list of documents should equal the amount of documents.\n",
    "print(\"The amount of documents found is: {}\".format(len(documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and remove garbage text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the leading/trailing whitespace from the documents.\n",
    "documents = [document.strip() for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all hyperlink-like text from the documents.\n",
    "hyperlinkExpression = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b(([-a-zA-Z0-9@:%_\\+.~#?&//=]|\\s*-)*)\"\n",
    "documents = [re.sub(hyperlinkExpression, '', document) for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on the above code**\n",
    "\n",
    "Removes hyperlinks of the form:<br>\n",
    "http://www.standaard.be/cnt/dmf20161129_02597674\n",
    "\n",
    "but also:<br>\n",
    "https://www.rijksoverheid.nl/actueel/nieuws/2016/11/03/minister-president<br>\n",
    "[WHITESPACE]-rutte-verzorgt-de-preek-van-de-leek\n",
    "\n",
    "but only the first line of: (last three lines remain as garbage text)<br>\n",
    "http://www.hln.be/hln/nl/4125/Internet/article/detail/2972254/2016/11/10/<br>\n",
    "[WHITESPACE]President<br>\n",
    "[WHITESPACE]-Trump-mag-twittervolgers-van-POTUS-houden.dhtml?utm_medium=rss&utm_content=ihln<br>\n",
    "[WHITESPACE]ophlnbehetallerlaatstenieuwsoverinternetgames\n",
    "\n",
    "If you can do any better, let me know :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removeTags(document):\n",
    "    forbiddenTags = [\"SECTION\", \"BYLINE\", \"LOAD-DATE\", \"LANGUAGE\", \"PUB-TYPE\", \"DATELINE\"]\n",
    "    documentSplit = document.split('\\n')\n",
    "    documentSplit = list(filter(None, documentSplit))\n",
    "    cleanDocument = [line for line in documentSplit if (not \"SECTION\" in line and not \"BYLINE\" in line and not \"LOAD-DATE\" in line and not \"LANGUAGE\" in line and not \"PUB-TYPE\" in line and not \"DATELINE\" in line)]\n",
    "    cleanDocument = \"\\n\".join(cleanDocument)\n",
    "    return cleanDocument\n",
    "\n",
    "documents = [removeTags(document) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeAuthor(document):\n",
    "    documentSplit = document.split('\\n')\n",
    "    documentSplit = list(filter(None, documentSplit))\n",
    "    cleanDocument = [line for line in documentSplit if (not line.startswith(\"Door\") and not line.startswith(\"door\") and not line.startswith(\"By\") and not line.startswith(\"by\"))]\n",
    "    cleanDocument = \"\\n\".join(cleanDocument)\n",
    "    return cleanDocument\n",
    "\n",
    "documents = [removeAuthor(document) for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the individual documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the folder where individual documents are stored.\n",
    "if not os.path.exists(DOCUMENTS_FOLDER):\n",
    "    os.makedirs(DOCUMENTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the documents to individual files as '[number].txt'\n",
    "for document in documents:\n",
    "    index = documents.index(document) + 1\n",
    "    with open('{}/{}.txt'.format(DOCUMENTS_FOLDER, index), 'w+') as writeFile:\n",
    "        writeFile.write(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the documents by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the titles of the documents.\n",
    "titles = []\n",
    "for document in documents:\n",
    "    documentSplit = document.split('\\n')\n",
    "    documentSplit = list(filter(None, documentSplit))\n",
    "\n",
    "    # Find the part that says 'LENGTH:', because...\n",
    "    lengthItem = next((s for s in documentSplit if 'LENGTH:' in s), None)\n",
    "    lengthIndex = documentSplit.index(lengthItem)\n",
    "    # ...the text is stored in the string one before the one that says 'LENGTH: xxx woorden'\n",
    "    title = documentSplit[lengthIndex-1]\n",
    "    titles.append(title)\n",
    "    \n",
    "print(\"The first five titles are:\\n{}\".format(titles[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the bodies of the documents.\n",
    "bodies = []\n",
    "for document in documents:\n",
    "    documentSplit = document.split('\\n')\n",
    "    documentSplit = list(filter(None, documentSplit))\n",
    "\n",
    "     # Find the part that says 'LENGTH:', because...\n",
    "    lengthItem = next((s for s in documentSplit if 'LENGTH:' in s), None)\n",
    "    lengthIndex = documentSplit.index(lengthItem)\n",
    "    # ...the text is stored in the strings one after the one that says 'LENGTH: xxx woorden'\n",
    "    text = ' '.join(documentSplit[lengthIndex+1:])\n",
    "    bodies.append(text)\n",
    "    \n",
    "print(\"The first five bodies are:\\n{}\".format(bodies[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the distribution dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create lists of all possible months to check for.\n",
    "MONTHS_DUTCH = [\"januari\", \"februari\", \"maart\", \"april\", \"mei\", \"juni\", \"juli\", \"augustus\", \"september\", \"oktober\", \"november\", \"december\"]\n",
    "MONTHS_ENGLISH = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "# Also create the capitalised versions of these months.\n",
    "MONTHS_DUTCH_CAPITAL = [month.capitalize() for month in MONTHS_DUTCH]\n",
    "MONTHS_ENGLISH_CAPITAL = [month.capitalize() for month in MONTHS_ENGLISH]\n",
    "\n",
    "# The possible months are all the months defined above.\n",
    "# Note that MONTHS_DUTCH and MONTHS_ENGLISH_CAPITAL should suffice,\n",
    "# but this isn't that much work and catches any human errors.\n",
    "# Turning into a 'set' first means that all copies will be reduced to simply one:\n",
    "#     [\"april\", \"april\", \"mei\", \"may\"] -> [\"april\", \"mei\", \"may\"]\n",
    "MONTHS = list(set(MONTHS_DUTCH + MONTHS_DUTCH_CAPITAL + MONTHS_ENGLISH + MONTHS_ENGLISH_CAPITAL))\n",
    "\n",
    "# Add a regular subexpression for each month to the general regular expression.\n",
    "# The final regular expression will match all kinds of variations using all months\n",
    "# in different positions.\n",
    "reMonth = []\n",
    "for month in MONTHS:\n",
    "    # Expression for dd mm yyyy\n",
    "    reMonth.append(r\"\\d\\d* {} \\d\\d\\d\\d\".format(month))\n",
    "    # Expression for mm dd yyyy\n",
    "    reMonth.append(r\"{} \\d\\d* \\d\\d\\d\\d\".format(month))\n",
    "    # Expression for dd mm, yyyy\n",
    "    reMonth.append(r\"\\d\\d* {}, \\d\\d\\d\\d\".format(month))\n",
    "    # Expression for mm dd, yyyy\n",
    "    reMonth.append(r\"{} \\d\\d*, \\d\\d\\d\\d\".format(month))\n",
    "dateExpression = \"(\" + '|'.join(reMonth) + \")\"\n",
    "\n",
    "print(\"Final date regular expression:\\n{}\".format(dateExpression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distributionDates = []\n",
    "for document in documents:\n",
    "    allDates = re.findall(dateExpression, document)\n",
    "    # Select the first date in the article and assume it is the distribution date.\n",
    "    # This is usually correct, as the documents start with a title and date.\n",
    "    try:\n",
    "        distributionDate = allDates[0]\n",
    "    except IndexError:\n",
    "        distributionDate = \"\"\n",
    "    distributionDates.append(distributionDate)\n",
    "\n",
    "print(\"The first five distribution dates are:\\n{}\".format(distributionDates[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and saving the aggregated documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create document objects for each document (for easier access to title, body and date).\n",
    "documents = [Document(titles[documents.index(document)], createDate(distributionDates[documents.index(document)]), bodies[documents.index(document)]) for document in documents]\n",
    "# Remove documents with an invalid date, these cannot be labelled properly.\n",
    "documents = [document for document in documents if document.date.isValid()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new folder for the per_year data.\n",
    "perYearRoot = 'per_year'\n",
    "if not os.path.exists(perYearRoot):\n",
    "    os.makedirs(perYearRoot)\n",
    "\n",
    "# Use the documents' dates to create yearly documents containing the title and\n",
    "# body of each article.\n",
    "# If the file of a year already exists, simply append to this document, thereby\n",
    "# aggregating the documents by year.\n",
    "for document in documents:\n",
    "    with open(\"{}/{}.txt\".format(perYearRoot, document.date.year), \"a+\") as outputFile:\n",
    "        outputFile.write(document.title + \"\\n\\n\")\n",
    "        outputFile.write(document.body + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done with preprocessing.\n",
    "\n",
    "The `documents` and `per_year` folder now contain documents that can be processed with for example NLTK.\n",
    "\n",
    "See `NLTK-Example.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
