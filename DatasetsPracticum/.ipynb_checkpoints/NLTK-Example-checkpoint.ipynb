{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the NLTK functions available.\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are not installed by default and need to be installed manually\n",
    "by invoking the following commands via the command line:\n",
    "\n",
    "To open a Python session:\n",
    "\n",
    "`> python`\n",
    "  \n",
    "Make nltk available:\n",
    "\n",
    "`> import nltk`\n",
    "  \n",
    "Start the NLTK downloader:\n",
    "\n",
    "`> nltk.download()`\n",
    "  \n",
    "Now a program starts, make sure that under\n",
    "* 'Corpora', alpino - Alpino Dutch Treebank\n",
    "* 'Corpora', treebank - Penn Treebank Sample\n",
    "* 'Models', averaged_perceptron_tagger - Averaged Perceptron Tagger\n",
    "* 'Models', maxent_treebank_pos_tagger - Treebank Part of Speech Tagger (Maximum entropy)\n",
    "* 'Models', tagset - Help on Tagsets\n",
    "\n",
    "is installed, or do so manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://www.nltk.org/book/ch02.html 1.9 Loading your own Corpus\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# Use the following root folder that contains the documents of interest.\n",
    "corpusRoot = './per_year'\n",
    "# Put all files in the root folder in a corpus.\n",
    "wordlists = PlaintextCorpusReader(corpusRoot, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print all file names in the corpus.\n",
    "print(\"These filenames are in folder {}\".format(corpusRoot))\n",
    "print(wordlists.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print all the words in this file.\n",
    "print(\"\\nThese words are in file 2016.txt\")\n",
    "print(wordlists.words('2016.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the words and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the words from this file.\n",
    "words = wordlists.words('2016.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make all words lowercase.\n",
    "words = [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter out all stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "words = [word for word in words if not word in stopwords.words('dutch')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the word frequencies.\n",
    "fdist = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the 10 most common words with their frequencies.\n",
    "print(\"\\nThese are the 10 most common words\")\n",
    "for word, frequency in fdist.most_common(10):\n",
    "    print(u'{}\\t{}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From http://www.nltk.org/book/ch05.html\n",
    "\n",
    "# Use the default Penn Treebank tagset.\n",
    "# A complete overview is available here http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "# Request help on a tag (definition & examples) with:\n",
    "print(\"\\nThe tag 'NN' means:\")\n",
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tag the words with parts of speech.\n",
    "taggedWords = nltk.pos_tag(words)\n",
    "print(\"\\nThe first 10 words are tagged as:\")\n",
    "print(taggedWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or using the Dutch tagger for more accurate results.\n",
    "# Created using: https://github.com/evanmiltenburg/Dutch-tagger\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "tagger = PerceptronTagger(load=False)\n",
    "tagger.load('model.perc.dutch_tagger_small.pickle')\n",
    "\n",
    "taggedWords = tagger.tag(words)\n",
    "print(\"\\nThe first 10 words are tagged as:\")\n",
    "print(taggedWords[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://www.nltk.org/howto/collocations.html\n",
    "import nltk.collocations\n",
    "import collections\n",
    "\n",
    "bgm = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(taggedWords)\n",
    "# Scored is a list of bigram tuples and their likelihood ratio:\n",
    "#   [((('word1', 'tag1'), ('word2', 'tag2')), likelihood ratio), ...]\n",
    "# For example:\n",
    "#   [((('de', 'IN'), ('president', 'NN'), 0.019015), ...]\n",
    "scored = finder.score_ngrams(bgm.likelihood_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter to contain only words tagged as 'nounsg'.\n",
    "scored = [x for x in scored if x[0][0][1] == 'nounsg']\n",
    "# Show the first 5 bigrams.\n",
    "print(\"\\nThe first bigrams found:\")\n",
    "print(scored[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group bigrams by first word in bigram.\n",
    "prefixKeys = collections.defaultdict(list)\n",
    "for key, scores in scored:\n",
    "    prefixKeys[key[0]].append((key[1], scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort keyed bigrams by strongest association.\n",
    "# Highly associated bigrams are placed first.\n",
    "for key in prefixKeys:\n",
    "    prefixKeys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "print(\"\\nThe best bigrams ordered by score:\")\n",
    "print(scored[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search the collocations for these words where they appear as 'nounsg'.\n",
    "print(\"\\nThe top 5 collocations found:\")\n",
    "print('president:', prefixKeys[('president', 'nounsg')][:5])\n",
    "print('zuid:', prefixKeys[('zuid', 'nounsg')][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is not a native function of NLTK.\n",
    "\n",
    "It is possible to use some other library, such as sci-kit learn.\n",
    "This library is installed with Anaconda.\n",
    "\n",
    "For examples, see\n",
    "http://www.bogotobogo.com/python/NLTK/tf_idf_with_scikit-learn_NLTK.php\n",
    "\n",
    "or the `Tf-Idf in Scikit-Learn` part of http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
